package crew_document

import (
	"context"
	"database/sql" // sql.NullInt64 ve sql.NullString iÃ§in eklendi
	"encoding/csv"
	"fmt"
	"log"
	"path/filepath" // Dosya uzantÄ±sÄ±nÄ± almak iÃ§in eklendi
	"strconv"
	"strings"
	"time" // Tarih dÃ¶nÃ¼ÅŸtÃ¼rme iÃ§in time paketi eklendi

	"mini_CMS_Desktop_App/db"
	"mini_CMS_Desktop_App/handlers/progress" // Progress bar iÃ§in import
	"mini_CMS_Desktop_App/models"

	"github.com/gofiber/fiber/v2"
	"github.com/google/uuid"      // UUID oluÅŸturmak iÃ§in
	"github.com/xuri/excelize/v2" // âœ… Excelize kÃ¼tÃ¼phanesi eklendi
)

// --- Helper Functions ---

// parseTimestampToNullInt64, string'i sql.NullInt64'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
// BoÅŸ stringler veya parse edilemeyenler iÃ§in geÃ§erli olmayan (Valid: false) bir sql.NullInt64 dÃ¶ndÃ¼rÃ¼r.
// Penalty handler'daki parseDateTimeToUnix gibi formatlÄ± tarih stringlerini de iÅŸleyebilir.
func parseTimestampToNullInt64(s string) (sql.NullInt64, error) {
	s = strings.TrimSpace(s)
	if s == "" {
		return sql.NullInt64{Valid: false}, nil // BoÅŸ string ise NULL olarak ayarla
	}

	// Ä°lk olarak doÄŸrudan int64 olarak parse etmeye Ã§alÄ±ÅŸ (Unix timestamp ise)
	val, err := strconv.ParseInt(s, 10, 64)
	if err == nil {
		return sql.NullInt64{Int64: val, Valid: true}, nil
	}

	// EÄŸer doÄŸrudan int64 deÄŸilse, tarih/saat stringi olarak parse etmeye Ã§alÄ±ÅŸ
	// "DD/MM/YYYY HH:MM:SS" formatÄ± iÃ§in (Penalty handler'daki format ile uyumlu)
	const dateTimeLayout = "02/01/2006 15:04:05" // GG/AA/YYYY SS:DD:SS
	t, err := time.Parse(dateTimeLayout, s)
	if err == nil {
		return sql.NullInt64{Int64: t.UnixNano() / int64(time.Millisecond), Valid: true}, nil // Milisaniye cinsinden
	}

	// BaÅŸka formatlar da denenebilir, Ã¶rneÄŸin "YYYY-MM-DD HH:MM:SS"
	const ymdhmsLayout = "2006-01-02 15:04:05"
	t, err = time.Parse(ymdhmsLayout, s)
	if err == nil {
		return sql.NullInt64{Int64: t.UnixNano() / int64(time.Millisecond), Valid: true}, nil
	}

	// HiÃ§bir format eÅŸleÅŸmezse veya parse edilemezse hata dÃ¶ndÃ¼r
	return sql.NullInt64{Valid: false}, fmt.Errorf("geÃ§ersiz tarih veya timestamp formatÄ±: '%s'", s)
}

// parseBool, string'i boolean'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
// Belirli TÃ¼rkÃ§e metinleri anlar: "Calisiyor", "Gecerli", "true", "1" -> true
// "Calismiyor", "Gecerli Degil", "false", "0" -> false
// BoÅŸ stringler veya bilinmeyen deÄŸerler iÃ§in false dÃ¶ndÃ¼rÃ¼r.
func parseBool(s string) (bool, error) {
	s = strings.TrimSpace(s)
	s = strings.ToLower(s)

	switch s {
	case "calisiyor", "gecerli", "true", "1":
		return true, nil
	case "calismiyor", "gecerli degil", "false", "0":
		return false, nil
	case "": // BoÅŸ string ise false kabul et (varsayÄ±lan davranÄ±ÅŸ)
		return false, nil
	default:
		return false, fmt.Errorf("bilinmeyen boolean deÄŸeri: '%s'", s)
	}
}

// --- Main Handler Function ---

// ImportCrewDocumentData, crew_documents tablosuna hem CSV hem de XLSX verisi aktarÄ±r.
// Fonksiyon adÄ± ImportCrewDocumentCSV'den ImportCrewDocumentData olarak deÄŸiÅŸtirildi.
func ImportCrewDocumentData(c *fiber.Ctx) error {
	log.Println("ğŸ” ImportCrewDocumentData Ã§aÄŸrÄ±ldÄ±")

	processID := c.Query("process_id")
	if processID == "" {
		processID = uuid.New().String()
		log.Printf("âš ï¸ process_id bulunamadÄ±, yeni bir tane oluÅŸturuldu: %s", processID)
	}
	progress.SendProgressUpdate(processID, 0, "YÃ¼kleme baÅŸlÄ±yor...")

	fileHeader, err := c.FormFile("file")
	if err != nil {
		log.Printf("âŒ Dosya alÄ±namadÄ±: %v", err)
		progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Dosya alÄ±namadÄ±: %v", err))
		return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": fmt.Sprintf("Dosya alÄ±namadÄ±: %v", err)})
	}

	file, err := fileHeader.Open()
	if err != nil {
		log.Printf("âŒ Dosya aÃ§Ä±lamadÄ±: %v", err)
		progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Dosya aÃ§Ä±lamadÄ±: %v", err))
		return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Dosya aÃ§Ä±lamadÄ±: %v", err)})
	}
	defer file.Close()

	var crewDocuments []models.CrewDocument
	recordCount := 0
	failedCount := 0
	lineNum := 0   // BaÅŸlÄ±k satÄ±rÄ±ndan sonraki veri satÄ±rlarÄ±nÄ± takip etmek iÃ§in (1'den baÅŸlar)
	totalRows := 0 // Toplam satÄ±r sayÄ±sÄ± tahmini (ilerleme Ã§ubuÄŸu iÃ§in daha doÄŸru bir tahmin)

	fileExtension := strings.ToLower(filepath.Ext(fileHeader.Filename))

	// Dosya boyutuna gÃ¶re kaba toplam satÄ±r sayÄ±sÄ±nÄ± tahmin et
	// Bu, progress bar iÃ§in daha iyi bir baÅŸlangÄ±Ã§ tahmini saÄŸlar.
	const avgLineLength = 200 // Ortalama satÄ±r uzunluÄŸu tahmini
	estimatedTotalRecords := int(fileHeader.Size) / avgLineLength
	if estimatedTotalRecords == 0 {
		estimatedTotalRecords = 1 // En az 1 kayÄ±t varsay
	}

	switch fileExtension {
	case ".csv":
		log.Println("Handling CSV file for Crew Document...")
		reader := csv.NewReader(file)
		reader.Comma = ';' // Sizin Ã¶rneÄŸinizde ';' ayracÄ± kullanÄ±lmÄ±ÅŸ
		reader.FieldsPerRecord = -1
		reader.LazyQuotes = true

		// TÃ¼m CSV satÄ±rlarÄ±nÄ± Ã¶nceden okuyarak toplam satÄ±r sayÄ±sÄ±nÄ± al
		// Bu, ilerleme Ã§ubuÄŸu iÃ§in daha doÄŸru bir 'totalRows' deÄŸeri saÄŸlar.
		allRecords, err := reader.ReadAll()
		if err != nil {
			log.Printf("âŒ CSV dosyasÄ± tamamÄ± okunamadÄ±: %v", err)
			progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: CSV dosyasÄ± okunamadÄ±: %v", err))
			return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("CSV dosyasÄ± okunamadÄ±: %v", err)})
		}

		if len(allRecords) < 2 { // BaÅŸlÄ±k satÄ±rÄ± + en az bir veri satÄ±rÄ± beklenir
			log.Println("âš ï¸ CSV dosyasÄ± boÅŸ veya sadece baÅŸlÄ±k satÄ±rÄ± iÃ§eriyor.")
			progress.SendProgressUpdate(processID, 100, "CSV dosyasÄ± boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor.")
			return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": "CSV dosyasÄ± boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor."})
		}

		header := allRecords[0] // BaÅŸlÄ±k satÄ±rÄ±
		log.Printf("ğŸ“Œ CSV Header: %s\n", strings.Join(header, ";"))

		totalRows = len(allRecords) - 1 // BaÅŸlÄ±k satÄ±rÄ±nÄ± Ã§Ä±kar
		if totalRows < 0 {
			totalRows = 0
		} // Negatif olmamasÄ± iÃ§in

		expectedColumnCount := 17 // CrewDocument modelindeki alan sayÄ±sÄ±
		if len(header) < expectedColumnCount {
			log.Printf("âŒ CSV baÅŸlÄ±k satÄ±rÄ± yetersiz sÃ¼tun iÃ§eriyor: %d yerine %d bekleniyor", len(header), expectedColumnCount)
			progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Yetersiz sÃ¼tun sayÄ±sÄ±: %d yerine %d bekleniyor", len(header), expectedColumnCount))
			return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": fmt.Sprintf("CSV baÅŸlÄ±k satÄ±rÄ± yetersiz sÃ¼tun iÃ§eriyor: %d yerine %d bekleniyor", len(header), expectedColumnCount)})
		}

		// Veri satÄ±rlarÄ±nÄ± iÅŸlemeye baÅŸla (baÅŸlÄ±k hariÃ§)
		for i, record := range allRecords[1:] {
			lineNum = i + 2 // GerÃ§ek dosya satÄ±r numarasÄ± (baÅŸlÄ±k+1'den baÅŸlar)

			if len(record) < expectedColumnCount {
				log.Printf("âš ï¸ SatÄ±r %d atlandÄ±: Yetersiz sÃ¼tun sayÄ±sÄ± (%d yerine %d bekleniyor)\n", lineNum, len(record), expectedColumnCount)
				failedCount++
				continue
			}

			// --- Veri TÃ¼rÃ¼ DÃ¶nÃ¼ÅŸÃ¼mleri ve TrimSpace ---
			// Personel bilgileri
			personelID := strings.TrimSpace(record[0])
			if personelID == "" {
				log.Printf("âŒ SatÄ±r %d, 'PersonID' alanÄ± boÅŸ. SatÄ±r atlandÄ±.\n", lineNum)
				failedCount++
				continue
			}

			gecerlilikBaslangicTarihi, err := parseTimestampToNullInt64(record[9])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'gecerlilik_baslangic_tarihi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			gecerlilikBitisTarihi, err := parseTimestampToNullInt64(record[10])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'gecerlilik_bitis_tarihi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			endDateLeaveJob, err := parseTimestampToNullInt64(record[13])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'end_date_leave_job' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			personelThyCalisiyorMu, err := parseBool(record[14])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'personel_thy_calisiyor_mu' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			dokumanGecerliMi, err := parseBool(record[15])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'dokuman_gecerli_mi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			var documentNo sql.NullString
			if strings.TrimSpace(record[11]) != "" {
				documentNo = sql.NullString{String: strings.TrimSpace(record[11]), Valid: true}
			} else {
				documentNo = sql.NullString{Valid: false}
			}

			var dokumaniVeren sql.NullString
			if strings.TrimSpace(record[12]) != "" {
				dokumaniVeren = sql.NullString{String: strings.TrimSpace(record[12]), Valid: true}
			} else {
				dokumaniVeren = sql.NullString{Valid: false}
			}

			crewDocument := models.CrewDocument{
				DataID:                    uuid.New(),
				PersonID:                  personelID,
				PersonSurname:             strings.TrimSpace(record[1]),
				PersonName:                strings.TrimSpace(record[2]),
				CitizenshipNumber:         strings.TrimSpace(record[3]),
				PersonType:                strings.TrimSpace(record[4]),
				UcucuAltTipi:              strings.TrimSpace(record[5]),
				UcucuSinifi:               strings.TrimSpace(record[6]),
				BaseFilo:                  strings.TrimSpace(record[7]),
				DokumanAltTipi:            strings.TrimSpace(record[8]),
				GecerlilikBaslangicTarihi: gecerlilikBaslangicTarihi,
				GecerlilikBitisTarihi:     gecerlilikBitisTarihi,
				DocumentNo:                documentNo,
				DokumaniVeren:             dokumaniVeren,
				EndDateLeaveJob:           endDateLeaveJob,
				PersonelThyCalisiyorMu:    personelThyCalisiyorMu,
				DokumanGecerliMi:          dokumanGecerliMi,
				AgreementType:             strings.TrimSpace(record[16]),
			}
			crewDocuments = append(crewDocuments, crewDocument)
			recordCount++

			// Progress update
			progressPercent := int(float64(recordCount) / float64(totalRows) * 90) // Total read/parse phase
			if progressPercent > 90 {
				progressPercent = 90
			} // Max at 90% for this phase
			progress.SendProgressUpdate(processID, progressPercent, fmt.Sprintf("%d/%d kayÄ±t iÅŸlendi...", recordCount, totalRows))
		}

	case ".xlsx":
		log.Println("Handling XLSX file for Crew Document...")
		f, err := excelize.OpenReader(file)
		if err != nil {
			log.Printf("âŒ Excel dosyasÄ± aÃ§Ä±lamadÄ±: %v", err)
			progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Excel dosyasÄ± aÃ§Ä±lamadÄ±: %v", err))
			return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Excel dosyasÄ± aÃ§Ä±lamadÄ±: %v", err)})
		}

		sheetList := f.GetSheetList()
		if len(sheetList) == 0 {
			log.Println("âš ï¸ Excel dosyasÄ±nda hiÃ§ sayfa bulunamadÄ±.")
			progress.SendProgressUpdate(processID, 100, "Excel dosyasÄ±na sayfa bulunamadÄ±.")
			return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": "Excel dosyasÄ±na sayfa bulunamadÄ±."})
		}
		sheetName := sheetList[0]
		log.Printf("â„¹ï¸ Okunan Excel sayfasÄ±: %s\n", sheetName)

		rows, err := f.GetRows(sheetName)
		if err != nil {
			log.Printf("âŒ Excel sayfasÄ±ndan satÄ±rlar okunamadÄ±: %v", err)
			progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Excel sayfasÄ±ndan veri okunamadÄ±: %v", err))
			return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Excel sayfasÄ±ndan veri okunamadÄ±: %v", err)})
		}

		if len(rows) < 2 { // BaÅŸlÄ±k satÄ±rÄ± + en az bir veri satÄ±rÄ± beklenir
			log.Println("âš ï¸ Excel dosyasÄ± boÅŸ veya sadece baÅŸlÄ±k satÄ±rÄ± iÃ§eriyor.")
			progress.SendProgressUpdate(processID, 100, "Excel dosyasÄ± boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor.")
			return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": "Excel dosyasÄ± boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor."})
		}

		header := rows[0]                                            // BaÅŸlÄ±k satÄ±rÄ±
		log.Printf("ğŸ“Œ XLSX Header: %s\n", strings.Join(header, ";")) // CSV gibi ';' ile ayÄ±rarak logla

		totalRows = len(rows) - 1 // BaÅŸlÄ±k satÄ±rÄ±nÄ± Ã§Ä±kar
		if totalRows < 0 {
			totalRows = 0
		}

		expectedColumnCount := 17 // CrewDocument modelindeki alan sayÄ±sÄ±
		if len(header) < expectedColumnCount {
			log.Printf("âŒ XLSX baÅŸlÄ±k satÄ±rÄ± yetersiz sÃ¼tun iÃ§eriyor: %d yerine %d bekleniyor\n", len(header), expectedColumnCount)
			progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Yetersiz sÃ¼tun sayÄ±sÄ±: %d yerine %d bekleniyor", len(header), expectedColumnCount))
			return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": fmt.Sprintf("XLSX baÅŸlÄ±k satÄ±rÄ± yetersiz sÃ¼tun iÃ§eriyor: %d yerine %d bekleniyor", len(header), expectedColumnCount)})
		}

		for i, row := range rows {
			if i == 0 { // BaÅŸlÄ±k satÄ±rÄ±nÄ± atla
				continue
			}
			lineNum = i + 1 // GerÃ§ek Excel satÄ±r numarasÄ± (1 tabanlÄ±)

			// BoÅŸ satÄ±rlarÄ± atla (tÃ¼m hÃ¼creleri boÅŸsa)
			if len(row) == 0 || strings.Join(row, "") == "" {
				continue
			}

			// SÃ¼tun sayÄ±sÄ± kontrolÃ¼
			if len(row) < expectedColumnCount {
				log.Printf("âš ï¸ SatÄ±r %d atlandÄ±: Yetersiz sÃ¼tun sayÄ±sÄ± (%d yerine %d bekleniyor)\n", lineNum, len(row), expectedColumnCount)
				failedCount++
				continue
			}

			// --- Veri TÃ¼rÃ¼ DÃ¶nÃ¼ÅŸÃ¼mleri ve TrimSpace ---
			personelID := strings.TrimSpace(row[0])
			if personelID == "" {
				log.Printf("âŒ SatÄ±r %d, 'PersonID' alanÄ± boÅŸ. SatÄ±r atlandÄ±.\n", lineNum)
				failedCount++
				continue
			}

			gecerlilikBaslangicTarihi, err := parseTimestampToNullInt64(row[9])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'gecerlilik_baslangic_tarihi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			gecerlilikBitisTarihi, err := parseTimestampToNullInt64(row[10])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'gecerlilik_bitis_tarihi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			endDateLeaveJob, err := parseTimestampToNullInt64(row[13])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'end_date_leave_job' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			personelThyCalisiyorMu, err := parseBool(row[14])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'personel_thy_calisiyor_mu' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			dokumanGecerliMi, err := parseBool(row[15])
			if err != nil {
				log.Printf("âŒ SatÄ±r %d, 'dokuman_gecerli_mi' dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: %v. SatÄ±r atlandÄ±.\n", lineNum, err)
				failedCount++
				continue
			}

			var documentNo sql.NullString
			if strings.TrimSpace(row[11]) != "" {
				documentNo = sql.NullString{String: strings.TrimSpace(row[11]), Valid: true}
			} else {
				documentNo = sql.NullString{Valid: false}
			}

			var dokumaniVeren sql.NullString
			if strings.TrimSpace(row[12]) != "" {
				dokumaniVeren = sql.NullString{String: strings.TrimSpace(row[12]), Valid: true}
			} else {
				dokumaniVeren = sql.NullString{Valid: false}
			}

			crewDocument := models.CrewDocument{
				DataID:                    uuid.New(),
				PersonID:                  personelID,
				PersonSurname:             strings.TrimSpace(row[1]),
				PersonName:                strings.TrimSpace(row[2]),
				CitizenshipNumber:         strings.TrimSpace(row[3]),
				PersonType:                strings.TrimSpace(row[4]),
				UcucuAltTipi:              strings.TrimSpace(row[5]),
				UcucuSinifi:               strings.TrimSpace(row[6]),
				BaseFilo:                  strings.TrimSpace(row[7]),
				DokumanAltTipi:            strings.TrimSpace(row[8]),
				GecerlilikBaslangicTarihi: gecerlilikBaslangicTarihi,
				GecerlilikBitisTarihi:     gecerlilikBitisTarihi,
				DocumentNo:                documentNo,
				DokumaniVeren:             dokumaniVeren,
				EndDateLeaveJob:           endDateLeaveJob,
				PersonelThyCalisiyorMu:    personelThyCalisiyorMu,
				DokumanGecerliMi:          dokumanGecerliMi,
				AgreementType:             strings.TrimSpace(row[16]),
			}
			crewDocuments = append(crewDocuments, crewDocument)
			recordCount++

			// Progress update
			progressPercent := int(float64(recordCount) / float64(totalRows) * 90)
			if progressPercent > 90 {
				progressPercent = 90
			}
			progress.SendProgressUpdate(processID, progressPercent, fmt.Sprintf("%d/%d kayÄ±t iÅŸlendi...", recordCount, totalRows))
		}

	default:
		log.Printf("âŒ Desteklenmeyen dosya uzantÄ±sÄ±: %s", fileExtension)
		progress.SendProgressUpdate(processID, 0, fmt.Sprintf("Hata: Desteklenmeyen dosya tipi: %s", fileExtension))
		return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": "Desteklenmeyen dosya tipi. LÃ¼tfen .csv veya .xlsx dosyasÄ± yÃ¼kleyin."})
	}

	if recordCount == 0 {
		log.Println("âš ï¸ Dosyada iÅŸlenecek hiÃ§ veri satÄ±rÄ± bulunamadÄ± (baÅŸlÄ±k hariÃ§).")
		progress.SendProgressUpdate(processID, 100, "Dosyada boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor.")
		return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{"error": "Dosyada boÅŸ veya hiÃ§ veri satÄ±rÄ± iÃ§ermiyor."})
	}

	log.Printf("ğŸš€ %d adet crew_document kaydÄ± veritabanÄ±na ekleniyor...\n", recordCount)

	// Phase: Delete Old Data (90-95%)
	deleteProgressStart := 90
	deleteProgressEnd := 95
	if c.QueryBool("reset", false) {
		log.Println("ğŸš€ 'reset=true' parametresi algÄ±landÄ±, mevcut ekip dokÃ¼manlarÄ± temizleniyor...")
		progress.SendProgressUpdate(processID, deleteProgressStart, "Mevcut veriler temizleniyor...")
		_, err := db.DB.NewDelete().
			Model(&models.CrewDocument{}).
			Where("TRUE").
			Exec(context.Background())
		if err != nil {
			log.Printf("âŒ Mevcut ekip dokÃ¼manlarÄ± temizlenirken hata oluÅŸtu: %v", err)
			progress.SendProgressUpdate(processID, 100, fmt.Sprintf("Hata: Mevcut veriler temizlenirken hata oluÅŸtu: %v", err))
			return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Mevcut veriler temizlenirken hata oluÅŸtu: %v", err)})
		}
		log.Println("âœ… Mevcut ekip dokÃ¼manlarÄ± baÅŸarÄ±yla temizlendi.")
		progress.SendProgressUpdate(processID, deleteProgressEnd, "Mevcut veriler temizlendi.")
	} else {
		// Reset yapÄ±lmadÄ±ysa bu aÅŸamayÄ± atla, progress'i de atla
		deleteProgressStart = 95
		deleteProgressEnd = 95
	}

	// Phase: Insert New Data (95-99%)
	insertProgressStart := deleteProgressEnd
	// Ä°lerleme Ã§ubuÄŸunun 99'a kadar gitmesi iÃ§in yÃ¼zde hesaplamasÄ±
	insertProgressPerRecord := float64(4) / float64(recordCount) // %4'lÃ¼k dilim (95'ten 99'a)
	progress.SendProgressUpdate(processID, insertProgressStart, fmt.Sprintf("%d kayÄ±t veritabanÄ±na ekleniyor...", recordCount))

	// â­ ON CONFLICT ifadesi kaldÄ±rÄ±ldÄ±
	// DataID hariÃ§ unique kÄ±sÄ±tlama olmadÄ±ÄŸÄ± iÃ§in ON CONFLICT kullanÄ±lmaz.
	// Yeni kayÄ±tlarÄ± ekler.
	tx, err := db.DB.BeginTx(context.Background(), nil) // Ä°ÅŸlem baÅŸlat
	if err != nil {
		log.Printf("âŒ Ä°ÅŸlem baÅŸlatÄ±lÄ±rken hata: %v", err)
		progress.SendProgressUpdate(processID, 100, fmt.Sprintf("Hata: Ä°ÅŸlem baÅŸlatÄ±lÄ±rken hata: %v", err))
		return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Ä°ÅŸlem baÅŸlatÄ±lÄ±rken hata: %v", err)})
	}
	defer tx.Rollback() // Hata olursa geri al

	// Her 1000 kayÄ±tta bir toplu ekleme yap (performans iÃ§in)
	batchSize := 1000
	for i := 0; i < len(crewDocuments); i += batchSize {
		end := i + batchSize
		if end > len(crewDocuments) {
			end = len(crewDocuments)
		}
		batch := crewDocuments[i:end]

		_, err := tx.NewInsert().
			Model(&batch).
			Exec(context.Background())
		if err != nil {
			log.Printf("âŒ VeritabanÄ±na toplu ekleme hatasÄ± (Batch %d-%d): %v", i, end, err)
			progress.SendProgressUpdate(processID, 100, fmt.Sprintf("Hata: VeritabanÄ±na toplu ekleme hatasÄ±: %v", err))
			return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"success": recordCount, "failed": failedCount, "error": fmt.Sprintf("VeritabanÄ±na ekleme hatasÄ±: %v", err)})
		}
		// Batch progress update
		currentProgress := insertProgressStart + int(float64(i+batchSize)/float64(recordCount)*insertProgressPerRecord)
		if currentProgress > 99 {
			currentProgress = 99
		}
		progress.SendProgressUpdate(processID, currentProgress, fmt.Sprintf("%d/%d kayÄ±t eklendi...", i+batchSize, recordCount))
	}

	if err := tx.Commit(); err != nil { // Ä°ÅŸlemi onayla
		log.Printf("âŒ Ä°ÅŸlem onaylanÄ±rken hata: %v", err)
		progress.SendProgressUpdate(processID, 100, fmt.Sprintf("Hata: Ä°ÅŸlem onaylanÄ±rken hata: %v", err))
		return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{"error": fmt.Sprintf("Ä°ÅŸlem onaylanÄ±rken hata: %v", err)})
	}

	progress.SendProgressUpdate(processID, 100, fmt.Sprintf("%d kayÄ±t baÅŸarÄ±yla eklendi.", recordCount))
	log.Printf("âœ… %d adet crew_document kaydÄ± baÅŸarÄ±yla eklendi. %d kayÄ±t atlandÄ±.\n", recordCount, failedCount)
	return c.Status(fiber.StatusOK).JSON(fiber.Map{"success": recordCount, "failed": failedCount, "message": fmt.Sprintf("%d kayÄ±t baÅŸarÄ±yla eklendi. %d kayÄ±t atlandÄ±.", recordCount, failedCount)})
}
